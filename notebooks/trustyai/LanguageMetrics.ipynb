{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e8b0192-d2b7-4a22-86c3-b5b5ede2644a",
   "metadata": {},
   "source": [
    "# Language metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ba61a3-9cff-4e11-a115-c27db8580fbb",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Language metrics are crucial in the field of Natural Language Processing (NLP) for measuring the similarity and differences between strings of text. One such metric is the Levenshtein distance, which calculates the minimum number of single-character edits (insertions, deletions, or substitutions) required to change one word into another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d29c4-8677-4bc7-a888-b0742ab9e3b7",
   "metadata": {},
   "source": [
    "## Levenshtein distance\n",
    "\n",
    "In this context, the Levenshtein distance is calculated based on tokens (which could be words, subwords, or other meaningful units) instead of individual characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8e3d7-c9b9-485c-92d1-752134528f91",
   "metadata": {},
   "source": [
    "### Basic Example: Token-Based Levenshtein Distance\n",
    "\n",
    "Let's begin with a simple token-based example, using whitespace as a basic tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953512cc-2520-4f37-ba19-bf7ed572cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Levenshtein import distance, editops\n",
    "\n",
    "A = \"kitten sitting\"\n",
    "B = \"sitting kitten\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0421671-4f0e-41d0-83b9-9473151d6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Levenshtein distance\n",
    "dist = distance(A, B)\n",
    "\n",
    "# Get the edit operations\n",
    "edits = editops(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bddb00b-0e83-4db0-ba2a-b0a233aa0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the operations\n",
    "substitutions = sum(1 for op in edits if op[0] == 'replace')\n",
    "deletions = sum(1 for op in edits if op[0] == 'delete')\n",
    "insertions = sum(1 for op in edits if op[0] == 'insert')\n",
    "correct = len(A) - deletions - substitutions\n",
    "\n",
    "print(f\"Substitutions: {substitutions}\")\n",
    "print(f\"Deletions: {deletions}\")\n",
    "print(f\"Insertions: {insertions}\")\n",
    "print(f\"Correct: {correct}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d233ca6-8bf5-4142-b126-be2bc2fd4dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the distance matrix\n",
    "def levenshtein_matrix(s1, s2):\n",
    "    m, n = len(s1), len(s2)\n",
    "    d = np.zeros((m + 1, n + 1))\n",
    "    for i in range(m + 1):\n",
    "        d[i, 0] = i\n",
    "    for j in range(n + 1):\n",
    "        d[0, j] = j\n",
    "    for j in range(1, n + 1):\n",
    "        for i in range(1, m + 1):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                d[i, j] = d[i - 1, j - 1]\n",
    "            else:\n",
    "                d[i, j] = min(d[i - 1, j] + 1, d[i, j - 1] + 1, d[i - 1, j - 1] + 1)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766c9c8-1aec-4467-84ad-516770ce52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distance matrix\n",
    "plt.imshow(matrix, cmap='viridis', origin='upper', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xlabel('String B')\n",
    "plt.ylabel('String A')\n",
    "plt.title('Levenshtein Distance Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a775170d-e762-49cc-a710-4b6dc72d0474",
   "metadata": {},
   "source": [
    "### Complex Example: Custom Tokenizer\n",
    "\n",
    "For more complex examples, especially relevant to LLMs, we might need a tokenizer that goes beyond simple whitespace separation. \n",
    "Let's create an alternate tokenizer and use it for our Levenshtein distance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17dd378-722b-43e7-9fa3-a26c4e6e141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    # Tokenize based on punctuation and whitespace\n",
    "    import re\n",
    "    tokens = re.findall(r'\\b\\w+\\b|\\S', text)\n",
    "    return tokens\n",
    "\n",
    "# Examples\n",
    "A = \"Renewable energy sources are essential for sustainable development.\"\n",
    "B = \"Sustainable development necessitates the use of renewable energy sources.\"\n",
    "\n",
    "# Compute and print token-based Levenshtein distance\n",
    "d = levenshtein(A, B, tokenizer=custom_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97ebd2-62c6-45b9-bbbb-5ccfc8e255f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(custom_tokenizer(A))\n",
    "print(custom_tokenizer(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e09575-877f-4052-85c3-53c0aadfd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3c828-3f9a-43ad-8a46-f9fc9bd79190",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Substitutions: {d.counters.substitutions}\")\n",
    "print(f\"Deletions: {d.counters.deletions}\")\n",
    "print(f\"Insertions: {d.counters.insertions}\")\n",
    "print(f\"Correct: {d.counters.correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d11d565-79ad-4dcd-86da-c1383ba27d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aecd6b6-99a2-4cd2-9e50-b6807742dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
